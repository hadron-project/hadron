Streams
=======
Streams are append-only, immutable logs of data.

## DDL
Streams are declared in YAML as part of the [Schema Management system](./schema.md). The DDL for the `Stream` object is as follows:

```yaml
## The kind of object being defined. In this case, a stream.
kind: Stream
## The spec of this object.
spec:
  ## The namespace in which this stream is to be created.
  namespace: required string
  ## The name of the stream. Each stream must have a unique name per namespace.
  name: required string

  ## This stream's type, defaults to `Standard`.
  ##
  ## Standard: A standard stream with a configurable number of partitions.
  ##
  ## OutTable: A single-partition stream optimized for use with a database
  ## "out table" CDC pattern.
  streamType: enum Standard | OutTable (default Standard)

  ## The number of partitions to create for this stream.
  partitions: required unsigned integer (default 1)

  ## The replication factor of each partition of this stream.
  replicationFactor: required unsigned integer (default 1)

  ## An optional TTL duration specifying how long records are to be kept on
  ## the stream.
  ##
  ## If not specified, then records will stay on the stream forever.
  ttl: optional duration (default none)
```

Streams can be updated the same way all other Hadron DDL objects can be updated. See the [Schema Management chapter](./schema.md) for more details.

## Stream Types
### Standard
An append-only, immutable log with a configurable number of partitions.

#### Details
- Stream names may be 1-100 characters long, containing only `[-_.a-zA-Z0-9]`. The `.` can be used to form hierarchies for authorization matching wildcards.
- Streams may have one or more partitions, which may be increased as needed. Horizontally scaling the Hadron cluster and adding more partitions to a stream will allow the write throughput of the stream to horizontally scale.
- Stream data is replicated accross cluster members based on the stream's replication factor. The Hadron cluster uses its own built-in Raft consensus system to assign stream partition leaders and followers for replication.
- Streams must first be created via the Hadron DDL system. See the [Schema Management](./schema.md) chapter for more details.

### OutTable
An append-only, immutable log with one partition and which is optimized to enforce server-side exactly-once guarantees using the common CDC "out table" pattern.

OutTable streams differ from Standard streams in that they are single-partition only, and every record published to the stream must have a pre-defined ID. If the ID of the record already exists on the stream, then the record will not be written to the log again, ensuring that there are no duplicates. Other than that, they are operationally the same as Standard streams.

When used in combination with the common CDC "out table" pattern, this provides a fully idempotent exactly-once producer pattern which is guaranteed by the Hadron cluster even if producers are not behaving correctly.

#### Usage
Using a Hadron OutTable stream effectively requires a few simple elements to be in place. The following is a list of general expectations for effective use; however, at the end of the list we describe the core requirement which may offer greater flexibility for use in other contexts.

- Events are being generated and written to a dedicated table (the event table) as part of a transaction system, typically a RDBMS. It is expected that each event will have a unique ID, typically a monotonically increasing integer generated by the database, though other values may be used as long as they are unique.
- Events will be written as part of the same business logic transactions, ensuring that events a generated atomically as part of the business logic update.
- Any number of application specific routines — or the Hadron OutTable Connector in the future — will be able to read the events from the event table, transactionally delete them, and then write them to the Hadron OutTable stream.
- Once the batch write to the Hadron stream has finished successfully, the transaction deleting the consumed events should be committed. A failure to committ the transaction will just cause the events to be redelivered, which is a no-op for Hadron OutTable streams. A failure to write the batch of events to Hadron should just cause the RDBMS transaction to rollback, which can later be retried.

This simple pattern provides a powerful integration point between transactional database systems which are optimized for transactional workflows, and ensures that events generated by the transactional system are moved to the Hadron cluster without the possibility of duplicates.

All in all, this pattern can be summarized as follows: records published to an OutTable stream must have a unique ID, and duplicates will be ignored.

## Subscriptions
Subscriptions represent a client's interest to consume data from a stream. Subscriptions are created when a client submits a subscription request. Subscription requests must specify the target stream to subscribe to and a name to use for the subscription.

**Consumers & groups:** clients which process records from a stream as part of a subscription are known as consumers. When multiple clients subscribe to the same stream using the same subscription name, this will dynamically form a consumer group and messages will be load-balanced across all members of the group. Consumers will receive all messages without any message level discrimination.

**Durable:** subscriptions are durable in the sense that the group's progress through the stream is stored on disk. Clients may disconnect at any time, and they will be automatically removed from the consumer group, and new consumers may be added to the group just as easily.

**Starting point:** when subscriptions are created, they may specify a starting point: first or latest. The starting point only affects the creation of the consumer group when a subscription is created.

**Subscription Config:** when creating a subscription, there are various configuration options which my be specified in order to control behavior.
- `maxParallelConsumers` (default none): the maximum number of consumers allowed to process messages in parallel. If set to 1, then only one consumer is allowed to process messages at a time for the consumer group.
- `serverPingInterval` (default 5s): the rate at which the server will ping a consumer to check for liveness. If the consumer fails to respond too many times, the server will sever the connection.
- `serverPingFailureThreshold` (default 2): the number of consecutive failed server-sent pings allowed before a consumer connection will be severed.

**Consumer Config:** each individual consumer within a group has its own isolated configuration options.
- `consumerPingInterval` (default 5s): the rate at which the consumer will ping the server to check for liveness. If the server fails to respond too many times, the consumer will sever the connection and try to establish a new connection.
- `consumerPingFailureThreshold` (default 2): the number of consecutive failed consumer-sent pings allowed before the consumer's connection will be severed and the connection will be retried.
- `batchSize` (default 100): the maximum number of messages which will be delivered to the consumer per batch.
- `batchWaitMillis` (default 500): the amount of time in milliseconds which the consumer should delay for its batch to fill. This only applies when the consumer's batch has been partially filled.

Subscriptions may be deleted using the `StreamUnsub` client API.

### Ack & Nack
Messages being consumed from a stream must be ack'ed. Once a message is ack'd, it will not be re-delivered again to the same consumer group.

Messages may be nack'ed, which will cause immediate redelivery by default. A redelivery timeout may be specified, which will cause a timeout to be applied before redelivery of the message to a consumer. Redelivery timeouts are not durable, and are held in-memory by Hadron.

If a client disconnects while it was processing unacknowledged messages, Hadron will redeliver those messages to other live consumers of the same subscription consumer group.

## Transactions
Clients may transactionally ack a stream message and or publish a set of messages to other streams all within a single transaction.
